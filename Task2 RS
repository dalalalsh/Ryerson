#Recommender Systems for Task2 dataset

# Recommender Systems 

# install following three packages in R
library(recommenderlab)
library(reshape2)
library(ggplot2)
require(devtools) 

# Get additional recommendation algorithms
install_github("sanealytics", "recommenderlabrats")

# Remove ALL column EXEPT custAttr1, custAttr2, target. We do not need it 
tr = train[,c("amount", "custAttr1","field1", "flag2", "flag3", "flag5", "target")]

#trmelt = melt(tr, id = "custAttr1", measure = c("amount", "field1", "flag2", "flag3", "flag5"), value = "target")

# Using acast to convert above data
g = acast(tr, custAttr1 ~ field1 + flag2 + flag3 + flag5)

# Check the class of g
class(g)


# Convert it as a matrix
R = as.matrix(g)

# Convert R into realRatingMatrix data structure
#   realRatingMatrix is a recommenderlab sparse-matrix like data-structure
r <- as(R, "realRatingMatrix")
r

# Exploring similarity data 

# first 6 users
similarity_users <- similarity(r[1:6, ], 
                               method = "cosine", 
                               which = "users")
as.matrix(similarity_users)
image(as.matrix(similarity_users), main = "User similarity")

# First 6 concatenated features
similarity_items <- similarity(r[, 1:6], method =
                                 "cosine", which = "items")
as.matrix(similarity_items)
image(as.matrix(similarity_items), main = "Movies similarity")

# Heatmap of the rating matrix
#image(r, main = "Heatmap of the rating matrix") # hard to read
image(r[1:20, 1:40], main = "Heatmap of the first 20 rows and 25 columns")


# Defining training/test sets

# Randomly shuffle the data
set.seed(2)
train = train[sample(nrow(train)),]

# Create 10 equally size folds
folds = cut(seq(1,nrow(train)),breaks=10,labels=FALSE)

i = 1
# Segement your data by fold using the which() function 
testIndexes = which(folds==i,arr.ind=TRUE)
testData = train[testIndexes, ]
trainData = train[-testIndexes, ]

#Or cross validation
n_fold <- 10
scheme <- evaluationScheme(data = r, 
                              method = "cross-validation",
                              k = n_fold, 
                              given = 40, 
                              goodRating = 1)   #hard to run too big
                              
                              
### Method 1 ########################## NO RESULTS YET

# creation of recommender model based on ubcf
Rec.ubcf <- Recommender(getData(scheme, "train"), "UBCF")
# creation of recommender model based on ibcf for comparison
Rec.ibcf <- Recommender(getData(scheme, "train"), "IBCF")

# making predictions on the test data set
p.ubcf <- predict(Rec.ubcf, getData(scheme, "known"), type="ratings")
# making predictions on the test data set
p.ibcf <- predict(Rec.ibcf, getData(scheme, "known"), type="ratings")

p.ubcf@data@x = ifelse(p.ubcf@data@x > 0.5,1,0)
p.ibcf@data@x = ifelse(p.ibcf@data@x > 0.5,1,0)

# obtaining the error metrics for both approaches and comparing them
# RMSE, MSE, and MAE
error.ubcf<-calcPredictionAccuracy(p.ubcf, getData(scheme, "unknown"))
error.ibcf<-calcPredictionAccuracy(p.ibcf, getData(scheme, "unknown"))
error <- rbind(error.ubcf,error.ibcf)
rownames(error) <- c("UBCF","IBCF")

# Accuracy
accuracy = c((1 - error[1,3])*100, (1 - error[2,3])*100)
error = cbind(error, accuracy)
error

#f-measure is missing add it 

### Method 2 ########################## NO RESULTS YET
# Create a recommender object (model) 
#   Run anyone of the following four code lines.
#     Do not run all four
#       They pertain to four different algorithms.
#        UBCF: User-based collaborative filtering
#        IBCF: Item-based collaborative filtering
#      Parameter 'method' decides similarity measure
#        Cosine or Jaccard
rec=Recommender(trainData,method="UBCF", param=list(normalize = "Z-score",method="Cosine",minRating=0))
rec=Recommender(trainData,method="UBCF", param=list(normalize = "Z-score",method="Jaccard",nn=5, minRating=0))
rec=Recommender(trainData,method="IBCF", param=list(normalize = "Z-score",method="Jaccard",minRating=0))
rec=Recommender(trainData,method="POPULAR")
rec=Recommender(trainData,method="SVD")
rec=Recommender(trainData,method="RSVD")

# Depending upon your selection, examine what you got
print(rec)
getModel(rec)

# Create predictions 
recom <- predict(rec, testData, type="ratings")
recom
